{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9380,"status":"ok","timestamp":1662532564888,"user":{"displayName":"Trang Nguyễn","userId":"03744434713628095341"},"user_tz":-420},"id":"DSdxNzTy8pUg","outputId":"0d8d2ab8-d45c-4631-d5de-77e84fdd9750"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras-ocr\n","  Downloading keras_ocr-0.9.1-py3-none-any.whl (42 kB)\n","\u001b[K     |████████████████████████████████| 42 kB 1.0 MB/s \n","\u001b[?25hCollecting validators\n","  Downloading validators-0.20.0.tar.gz (30 kB)\n","Requirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from keras-ocr) (0.5.3)\n","Collecting essential_generators\n","  Downloading essential_generators-1.0-py3-none-any.whl (9.5 MB)\n","\u001b[K     |████████████████████████████████| 9.5 MB 8.2 MB/s \n","\u001b[?25hCollecting efficientnet==1.0.0\n","  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-ocr) (4.64.0)\n","Collecting fonttools\n","  Downloading fonttools-4.37.1-py3-none-any.whl (957 kB)\n","\u001b[K     |████████████████████████████████| 957 kB 58.0 MB/s \n","\u001b[?25hCollecting pyclipper\n","  Downloading pyclipper-1.3.0.post3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (604 kB)\n","\u001b[K     |████████████████████████████████| 604 kB 65.0 MB/s \n","\u001b[?25hRequirement already satisfied: shapely in /usr/local/lib/python3.7/dist-packages (from keras-ocr) (1.8.4)\n","Requirement already satisfied: imgaug in /usr/local/lib/python3.7/dist-packages (from keras-ocr) (0.4.0)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet==1.0.0->keras-ocr) (0.18.3)\n","Collecting keras-applications<=1.0.8,>=1.0.7\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 7.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0->keras-ocr) (1.21.6)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0->keras-ocr) (3.1.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0->keras-ocr) (1.5.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug->keras-ocr) (1.15.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug->keras-ocr) (1.7.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug->keras-ocr) (3.2.2)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug->keras-ocr) (4.6.0.66)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug->keras-ocr) (2.9.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug->keras-ocr) (7.1.2)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (2.6.3)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (2021.11.2)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr) (1.3.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug->keras-ocr) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug->keras-ocr) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug->keras-ocr) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug->keras-ocr) (0.11.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug->keras-ocr) (4.1.1)\n","Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from validators->keras-ocr) (4.4.2)\n","Building wheels for collected packages: validators\n","  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19582 sha256=3bb1da29174659b8d630232dfd7c1a3f689c412d3f7a7aa69b75d61f8e26d74c\n","  Stored in directory: /root/.cache/pip/wheels/5f/55/ab/36a76989f7f88d9ca7b1f68da6d94252bb6a8d6ad4f18e04e9\n","Successfully built validators\n","Installing collected packages: keras-applications, validators, pyclipper, fonttools, essential-generators, efficientnet, keras-ocr\n","Successfully installed efficientnet-1.0.0 essential-generators-1.0 fonttools-4.37.1 keras-applications-1.0.8 keras-ocr-0.9.1 pyclipper-1.3.0.post3 validators-0.20.0\n"]}],"source":["!pip install keras-ocr"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1662536015172,"user":{"displayName":"Trang Nguyễn","userId":"03744434713628095341"},"user_tz":-420},"id":"Xqi0pV2d3uKH"},"outputs":[],"source":["import os\n","import math\n","import imgaug\n","#A library for image augmentation in machine learning experiments, \n","#particularly convolutional neural networks. Supports the augmentation of images\n","#, keypoints/landmarks, bounding boxes, heatmaps and \n","#segmentation maps in a variety of different ways.\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import sklearn.model_selection\n","import tensorflow as tf\n","import keras_ocr\n","import typing"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":460,"status":"ok","timestamp":1662532577238,"user":{"displayName":"Trang Nguyễn","userId":"03744434713628095341"},"user_tz":-420},"id":"41kjoMpj4XTO"},"outputs":[],"source":["data_dir = '.'"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":263,"status":"ok","timestamp":1662532579394,"user":{"displayName":"Trang Nguyễn","userId":"03744434713628095341"},"user_tz":-420},"id":"XOoPME3K4d56"},"outputs":[],"source":["def get_dataset(training_gt_dir,training_images_dir,skip_illegible=False):\n","  dataset=[]\n","  image_files_name = os.listdir(training_images_dir)\n","  label_files_name = os.listdir(training_gt_dir)\n","  for image_file, label_file in zip(image_files_name,label_files_name):\n","        image_path = os.path.join(training_images_dir, image_file )\n","        lines = []\n","        with open(os.path.join(training_gt_dir, label_file), \"r\", encoding=\"utf8\") as f:\n","            current_line: typing.List[typing.Tuple[np.ndarray, str]] = []\n","            for raw_row in f.read().split(\"\\n\"):\n","                if raw_row == \"\":\n","                    lines.append(current_line)\n","                    current_line = []\n","                else:\n","                    row = raw_row.split(\" \")[4:]\n","                    #take from the 4th element onwards\n","                    character = row[-1][1:-1]\n","                    #the last element is the letter\n","                    if character == \"\" and skip_illegible:\n","                        continue\n","                    x1, y1, x2, y2 = map(float, row[:4])\n","                    #get 4 final coordinates of file label execpt last letter\n","                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n","                    #cast type to int\n","                    current_line.append(\n","                        (np.array([[x1, y1], [x2, y1], [x2, y2], [x1, y2]]), character)\n","                    )\n","        lines = [line for line in lines if line]\n","        dataset.append((image_path, lines, 1))\n","  return dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":441,"status":"ok","timestamp":1662532581927,"user":{"displayName":"Trang Nguyễn","userId":"03744434713628095341"},"user_tz":-420},"id":"pUN46xKH4gWF"},"outputs":[],"source":["training_gt_dir=\"/content/drive/MyDrive/OCR/Keras/dataset/labels\"\n","training_images_dir=\"/content/drive/MyDrive/OCR/Keras/dataset/image\""]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":33108,"status":"ok","timestamp":1662532616606,"user":{"displayName":"Trang Nguyễn","userId":"03744434713628095341"},"user_tz":-420},"id":"WnpSF69F4iZV"},"outputs":[],"source":["dataset=get_dataset(training_gt_dir,training_images_dir,skip_illegible=False)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":431,"status":"ok","timestamp":1662532621195,"user":{"displayName":"Trang Nguyễn","userId":"03744434713628095341"},"user_tz":-420},"id":"6iqdRwzj6HMS"},"outputs":[],"source":["train, validation = sklearn.model_selection.train_test_split(\n","    dataset, train_size=0.8, random_state=42\n",")\n","augmenter = imgaug.augmenters.Sequential([\n","    imgaug.augmenters.Affine(\n","      scale=(1.0, 1.2),\n","      rotate=(-5, 5)\n","      # Apply affine transformations to each image.\n","      # Scale/zoom them, translate/move them, rotate them and shear them.\n","    ),\n","    imgaug.augmenters.GaussianBlur(sigma=(0, 0.5)),\n","    #Strengthen or weaken the contrast in each image.\n","    imgaug.augmenters.Multiply((0.8, 1.2), per_channel=0.2)\n","    # Make some images brighter and some darker.\n","    # In 20% of all cases, we sample the multiplier once per channel,\n","    # which can end up changing the color of the images.\n","])\n","generator_kwargs = {'width': 640, 'height': 640}\n","training_image_generator = keras_ocr.datasets.get_detector_image_generator(\n","    labels=train,\n","    augmenter=augmenter,\n","    **generator_kwargs\n",")\n","validation_image_generator = keras_ocr.datasets.get_detector_image_generator(\n","    labels=validation,\n","    **generator_kwargs\n",")"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jUIqf21C6KDq","executionInfo":{"status":"ok","timestamp":1662535964344,"user_tz":-420,"elapsed":3341398,"user":{"displayName":"Trang Nguyễn","userId":"03744434713628095341"}},"outputId":"7ff3f922-ef16-4d9a-9d74-5e24b10df3e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking for /root/.keras-ocr/craft_mlt_25k.h5\n","Downloading /root/.keras-ocr/craft_mlt_25k.h5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/1000\n","960/960 [==============================] - ETA: 0s - loss: 0.0036"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras_ocr/tools.py:580: RuntimeWarning: invalid value encountered in double_scalars\n","  rotation = np.arctan((tl[0] - bl[0]) / (tl[1] - bl[1]))\n","/usr/local/lib/python3.7/dist-packages/keras_ocr/tools.py:580: RuntimeWarning: invalid value encountered in long_scalars\n","  rotation = np.arctan((tl[0] - bl[0]) / (tl[1] - bl[1]))\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r960/960 [==============================] - 688s 698ms/step - loss: 0.0036 - val_loss: 0.4081\n","Epoch 2/1000\n","960/960 [==============================] - 378s 393ms/step - loss: 0.0027 - val_loss: 0.4038\n","Epoch 3/1000\n","960/960 [==============================] - 378s 394ms/step - loss: 0.0036 - val_loss: 0.3965\n","Epoch 4/1000\n","960/960 [==============================] - 377s 393ms/step - loss: 0.0029 - val_loss: 0.4070\n","Epoch 5/1000\n","960/960 [==============================] - 379s 395ms/step - loss: 0.0025 - val_loss: 0.4041\n","Epoch 6/1000\n","960/960 [==============================] - 377s 393ms/step - loss: 0.0036 - val_loss: 0.4035\n","Epoch 7/1000\n","960/960 [==============================] - 379s 394ms/step - loss: 0.0027 - val_loss: 0.4082\n","Epoch 8/1000\n","960/960 [==============================] - 377s 393ms/step - loss: 0.0034 - val_loss: 0.4012\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fa0b046cf50>"]},"metadata":{},"execution_count":8}],"source":["detector = keras_ocr.detection.Detector()\n","\n","batch_size = 1\n","training_generator, validation_generator = [\n","    detector.get_batch_generator(\n","        image_generator=image_generator, batch_size=batch_size\n","    ) for image_generator in\n","    [training_image_generator, validation_image_generator]\n","]\n","detector.model.fit_generator(\n","    generator=training_generator,\n","    steps_per_epoch=math.ceil(len(train) / batch_size),\n","    epochs=1000,\n","    workers=0,\n","    callbacks=[\n","        tf.keras.callbacks.EarlyStopping(restore_best_weights=True, patience=5),\n","        #patince: number of epochs with no improvement after which training will be stopped\n","        #the loss for 5 consecutive epochs.\n","        tf.keras.callbacks.CSVLogger(os.path.join(data_dir, 'detector_keras.csv')),\n","        #Callback that streams epoch results to a CSV file.\n","        tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(data_dir, '/content/drive/MyDrive/detector_icdar2013.h5'))\n","        #Callback to save the Keras model or model weights at some frequency.\n","    ],\n","\n","    validation_data=validation_generator,\n","    validation_steps=math.ceil(len(validation) / batch_size)\n",")\n","#val_loss: quantity to be monitored."]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"mount_file_id":"1mDTaSdpmfyZL7ILU1DIQIGeh_s_bRdQz","authorship_tag":"ABX9TyMfX3q6AT8EvZN7H2vjPD4g"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}